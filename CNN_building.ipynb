{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48da0b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929c0e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3c2bb8",
   "metadata": {},
   "source": [
    "## CIFAR10 consists of 10 different types of images\n",
    "#### Like airoplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
    "#### 50k training images and 10k testing images 32*32 RGB pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b3a11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b11147c",
   "metadata": {},
   "source": [
    "## STEP-1: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f257a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 671s 4us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test,y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35451550",
   "metadata": {},
   "source": [
    "## Step-2: convert to \"float32\" and normalize to 0-1 by dividing with 255\n",
    "#### Float32 for better computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e1642a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef385b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be59c58",
   "metadata": {},
   "source": [
    "## STEP-3: Building using Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6d3568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "[\n",
    "    keras.Input(shape=(32,32,3)),\n",
    "    layers.Conv2D(32, (3,3), padding='valid', activation='relu'),  \n",
    "    #32 for number of convolutional channels/ (3,3) or 3 kernal size/ \n",
    "    #padding 'valid' or 'same' valid is default and output channel size is 30\n",
    "    # for same it maintain same size 32\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d669c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "612f97e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "[\n",
    "    keras.Input(shape=(32,32,3)),\n",
    "    layers.Conv2D(32, (3,3), padding='valid', activation='relu'),  \n",
    "    #32 for number of convolutional channels/ (3,3) or 3 kernal size/ \n",
    "    #padding 'valid' or 'same' valid is default and output channel size is 30\n",
    "    # for same it maintain same size 32\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(128, 3, activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3503919",
   "metadata": {},
   "source": [
    "## STEP-4 Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cafb2598",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 3e-4),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fe3bb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                131136    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225,034\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2029b74a",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6938c1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 - 56s - loss: 1.6502 - accuracy: 0.4000 - 56s/epoch - 72ms/step\n",
      "Epoch 2/10\n",
      "782/782 - 53s - loss: 1.3190 - accuracy: 0.5310 - 53s/epoch - 68ms/step\n",
      "Epoch 3/10\n",
      "782/782 - 53s - loss: 1.1815 - accuracy: 0.5823 - 53s/epoch - 68ms/step\n",
      "Epoch 4/10\n",
      "782/782 - 53s - loss: 1.0812 - accuracy: 0.6236 - 53s/epoch - 68ms/step\n",
      "Epoch 5/10\n",
      "782/782 - 53s - loss: 1.0077 - accuracy: 0.6503 - 53s/epoch - 68ms/step\n",
      "Epoch 6/10\n",
      "782/782 - 53s - loss: 0.9398 - accuracy: 0.6720 - 53s/epoch - 68ms/step\n",
      "Epoch 7/10\n",
      "782/782 - 53s - loss: 0.8893 - accuracy: 0.6910 - 53s/epoch - 68ms/step\n",
      "Epoch 8/10\n",
      "782/782 - 53s - loss: 0.8480 - accuracy: 0.7073 - 53s/epoch - 68ms/step\n",
      "Epoch 9/10\n",
      "782/782 - 53s - loss: 0.8039 - accuracy: 0.7223 - 53s/epoch - 68ms/step\n",
      "Epoch 10/10\n",
      "782/782 - 54s - loss: 0.7671 - accuracy: 0.7345 - 54s/epoch - 69ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1380017a8b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2792aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 - 3s - loss: 0.8561 - accuracy: 0.7060 - 3s/epoch - 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8561049103736877, 0.7059999704360962]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size = 64, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397d14aa",
   "metadata": {},
   "source": [
    "## Building using Functional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840591af",
   "metadata": {},
   "source": [
    "Batch normalization is a layer that allows every layer of the network to do learning more independently. It is used to normalize the output of the previous layers. The activations scale the input layer in normalization. Using batch normalization learning becomes efficient also it can be used as regularization to avoid overfitting of the model. The layer is added to the sequential model to standardize the input or the outputs. It can be used at several points in between the layers of the model. It is often placed just after defining the sequential model and after the convolution and pooling layers. The below code shows how to define the BatchNormalization layer for the classification of handwritten digits. We will first import the required libraries and the dataset. Use the below code for the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77b28d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model():\n",
    "    inputs = keras.Input(shape=(32,32,3))\n",
    "    x = layers.Conv2D(32,3)(inputs) # no activation due to we use batch normalization\n",
    "    x = layers.BatchNormalization()(x)                # after batch normalization we can use activation\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64,5,padding='same')(x) \n",
    "    x = layers.BatchNormalization()(x)               \n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.Conv2D(128,3)(x)\n",
    "    x = layers.BatchNormalization()(x)               \n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    outputs = layers.Dense(10)(x)\n",
    "    modelf = keras.Model(inputs=inputs, outputs = outputs)\n",
    "    return modelf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "281dc644",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d203c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 30, 30, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " tf.nn.relu_3 (TFOpLambda)   (None, 30, 30, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 15, 15, 64)        51264     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 15, 15, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " tf.nn.relu_4 (TFOpLambda)   (None, 15, 15, 64)        0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 13, 13, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 13, 13, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " tf.nn.relu_5 (TFOpLambda)   (None, 13, 13, 128)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 21632)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                1384512   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,512,074\n",
      "Trainable params: 1,511,626\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "523b9a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 3e-4),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93162f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 - 191s - loss: 1.2747 - accuracy: 0.5479 - 191s/epoch - 244ms/step\n",
      "Epoch 2/10\n",
      "782/782 - 194s - loss: 0.8646 - accuracy: 0.6974 - 194s/epoch - 247ms/step\n",
      "Epoch 3/10\n",
      "782/782 - 192s - loss: 0.7133 - accuracy: 0.7523 - 192s/epoch - 245ms/step\n",
      "Epoch 4/10\n",
      "782/782 - 191s - loss: 0.6085 - accuracy: 0.7882 - 191s/epoch - 245ms/step\n",
      "Epoch 5/10\n",
      "782/782 - 192s - loss: 0.5195 - accuracy: 0.8222 - 192s/epoch - 246ms/step\n",
      "Epoch 6/10\n",
      "782/782 - 192s - loss: 0.4424 - accuracy: 0.8496 - 192s/epoch - 245ms/step\n",
      "Epoch 7/10\n",
      "782/782 - 191s - loss: 0.3666 - accuracy: 0.8766 - 191s/epoch - 245ms/step\n",
      "Epoch 8/10\n",
      "782/782 - 191s - loss: 0.3152 - accuracy: 0.8931 - 191s/epoch - 244ms/step\n",
      "Epoch 9/10\n",
      "782/782 - 192s - loss: 0.2483 - accuracy: 0.9192 - 192s/epoch - 246ms/step\n",
      "Epoch 10/10\n",
      "782/782 - 192s - loss: 0.1984 - accuracy: 0.9373 - 192s/epoch - 245ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x138048fb940>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size = 64, epochs = 10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae3ef072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 - 11s - loss: 0.9856 - accuracy: 0.7234 - 11s/epoch - 67ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9856141805648804, 0.7233999967575073]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size = 64, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbcf24a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
